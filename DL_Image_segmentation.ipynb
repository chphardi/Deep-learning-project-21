{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "207e05ac",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-04T20:36:30.529567Z",
          "start_time": "2023-11-04T20:36:30.510549Z"
        },
        "id": "207e05ac"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import skimage.io as io\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image, ImageColor\n",
        "from scipy import ndimage\n",
        "from torch.utils.data import Dataset\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "#!pip install torchmetrics\n",
        "from torchmetrics.classification import Dice\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "drive_path = 'drive/My Drive/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8QX28rPHzZH",
        "outputId": "b8aebc66-eb3c-4903-d713-d94de22010e4"
      },
      "id": "l8QX28rPHzZH",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ca547f91",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-04T21:07:06.308385Z",
          "start_time": "2023-11-04T21:07:06.293404Z"
        },
        "id": "ca547f91"
      },
      "outputs": [],
      "source": [
        "parts = {10: {'col': 'orange', 'name':'hood'},\n",
        "         20: {'col':'darkgreen', 'name':'front door'},\n",
        "         30: {'col':'yellow', 'name':'rear door'},\n",
        "         40: {'col':'cyan', 'name':'frame'},\n",
        "         50: {'col':'purple', 'name':'rear quarter panel'},\n",
        "         60: {'col':'lightgreen', 'name':'trunk lid'},\n",
        "         70: {'col':'blue', 'name':'fender'},\n",
        "         80: {'col':'pink', 'name':'bumper'},\n",
        "         90: {'col':'darkgray', 'name':'rest of car'},\n",
        "         0 : {'col':'black', 'name':'background'}}\n",
        "\n",
        "def display_car(data_arr):\n",
        "    # Can take both full data and already split data\n",
        "    if type(data_arr) == torch.Tensor: data_arr = np.moveaxis(data_arr.numpy().astype(np.uint8), 0, 2)\n",
        "    elif data_arr.shape[0] == 3: data_arr = np.moveaxis(data_arr.astype(np.uint8), 0, 2)\n",
        "    elif data_arr.shape[2] > 3: data_arr = data_arr[:,:,:3]\n",
        "    img = Image.fromarray(data_arr)\n",
        "    display(img) # img.show() for jupyter\n",
        "\n",
        "def display_labels(data_arr):\n",
        "    # Can take both full data and already split data\n",
        "    if type(data_arr) == torch.Tensor: data_arr = data_arr.numpy()\n",
        "    if data_arr.dtype != np.uint8: data_arr = data_arr.astype(np.uint8)*10\n",
        "    if data_arr.ndim > 2: data_arr = data_arr[:,:,3]\n",
        "    img = Image.fromarray(data_arr)\n",
        "    pixels = list(img.getdata())\n",
        "    pixels = [ImageColor.getrgb(parts.get(pixel)['col']) for pixel in pixels]\n",
        "    image = Image.new(\"RGB\", (256, 256), (0,0,0))\n",
        "    image.putdata(pixels)\n",
        "    display(image)\n",
        "\n",
        "def numpy_to_tensor(arr):\n",
        "    return np.moveaxis(arr, 2, 0).astype(np.float32)\n",
        "\n",
        "def tensor_to_numpy(tens):\n",
        "    arr = np.moveaxis(tens, 0, 2).astype(np.uint8)\n",
        "    return arr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def center_square(img):\n",
        "    \"\"\"Returns the cropped central square of an image (crops the largest dimension to match the smallest one)\"\"\"\n",
        "    if img.size[0] == img.size[1]: return img\n",
        "    smallest_dim = np.argmin(img.size)\n",
        "    largest_dim = np.argmax(img.size)\n",
        "    square_dim = img.size[smallest_dim]\n",
        "    crop_dims = [0,0,0,0]\n",
        "    crop_dims[largest_dim] = int(img.size[largest_dim]/2-square_dim/2)\n",
        "    crop_dims[largest_dim+2] = int(img.size[largest_dim]/2+square_dim/2)\n",
        "    crop_dims[smallest_dim] = 0\n",
        "    crop_dims[smallest_dim+2] = img.size[smallest_dim]\n",
        "    crop_img = img.crop(crop_dims)\n",
        "\n",
        "    return crop_img\n",
        "\n",
        "def set_background(car_arr, labels_arr, img):\n",
        "    \"\"\"Places all non-0 pixels of the car on the background img\"\"\"\n",
        "    center_img = center_square(img)\n",
        "    back_arr = np.array(center_img.resize(labels_arr.shape))\n",
        "    # Use both car and labels just in case\n",
        "    back_arr[labels_arr!=0] = car_arr[labels_arr!=0]\n",
        "\n",
        "    # In the black car dataset, label pixel count should be similar to non-black pixel count\n",
        "    if np.sum(car_arr!=0)/3 < np.sum(labels_arr!=0)*1.2:\n",
        "        # In the black dataset, part of the car isn't correctly labeled, so also use car data for setting background\n",
        "        back_arr[car_arr!=0] = car_arr[car_arr!=0]\n",
        "\n",
        "    return back_arr\n",
        "\n",
        "def move_full_car(arr, x, y, angle=0, zoom=1):\n",
        "    \"\"\"Moves the center of the car to (x, y). Takes the whole array (car AND labels)\"\"\"\n",
        "    car_idxs = np.where(arr!=0)\n",
        "    car_bbox = [max(0,np.min(car_idxs[1])-10), max(0,np.min(car_idxs[0])-10), min(255, np.max(car_idxs[1])+10), min(255,np.max(car_idxs[0])+10)]\n",
        "    # Array with just the car\n",
        "    car_arr = arr[car_bbox[1]:car_bbox[3],car_bbox[0]:car_bbox[2]]\n",
        "    # Rotate the car\n",
        "    car_arr = ndimage.rotate(car_arr, angle, reshape=True, order=0)\n",
        "    car_arr = ndimage.zoom(car_arr, (zoom, zoom, 1), order=0)\n",
        "    # Edges of the car in the new array (without taking into account new image borders)\n",
        "    edges = [y-np.ceil(car_arr.shape[0]/2),y+np.floor(car_arr.shape[0]/2),x-np.ceil(car_arr.shape[1]/2),x+np.floor(car_arr.shape[1]/2)]\n",
        "    # Where to crop the car if it goes off bounds\n",
        "    car_limits = [max(0,-1*int(edges[0])), 255-int(edges[1]) if 255-int(edges[1]) < 0 else car_arr.shape[0], max(0,-1*int(edges[2])), 255-int(edges[3]) if 255-int(edges[3]) < 0 else car_arr.shape[1]]\n",
        "    edges = [max(0,int(edges[0])), min(255, int(edges[1])), max(0,int(edges[2])), min(255, int(edges[3]))]\n",
        "\n",
        "    new_arr = np.zeros(arr.shape)\n",
        "    new_arr[edges[0]:edges[1],edges[2]:edges[3]] = car_arr[car_limits[0]:car_limits[1],car_limits[2]:car_limits[3]]\n",
        "\n",
        "    return new_arr.astype(np.uint8)\n"
      ],
      "metadata": {
        "id": "7yikSHC1CRkE"
      },
      "id": "7yikSHC1CRkE",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_from_folder(folder_path, resize_shape=(256, 256), limit=100):\n",
        "    background_list = []\n",
        "    count = 0\n",
        "\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Check if the file is an image file\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "        background = Image.open(file_path).convert('RGB')\n",
        "        background_list.append(background)\n",
        "\n",
        "        count += 1\n",
        "        if count >= limit:\n",
        "            break\n",
        "\n",
        "    return background_list\n",
        "\n",
        "# Example usage:\n",
        "folder_path = 'drive/My Drive/carseg_data/images/landscapes'\n",
        "background_list = load_images_from_folder(folder_path, limit=250)"
      ],
      "metadata": {
        "id": "qeEpKGNqKlJ9"
      },
      "id": "qeEpKGNqKlJ9",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CarDataset(Dataset):\n",
        "    def __init__(self, root, file_list: list=None, backgrounds: list=[], move_car: bool=False, rotate_car: bool=False, zoom_car: bool=False):\n",
        "        \"\"\"\n",
        "        Initializes the dataset.\n",
        "        Parameters:\n",
        "            file_list: a list of filenames from 'root' to use. If not specified, all files will be used.\n",
        "            background: list with backgrounds. If not specified, no backgrounds will be used.\n",
        "            move_car: specifies if the cars should be moved to a random location in the image\n",
        "            rotate_car: specifies if the cars should be given a random rotation (within a range)\n",
        "        Backgrounds, rotations and translations are random. There is a chance that none will be performed at all.\n",
        "        This chance is higher for 'photo' images, which will only be rotated/translated when the background is changed (to avoid black bars)\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.filenames = os.listdir(self.root) if file_list is None else file_list\n",
        "        self.backgrounds = backgrounds\n",
        "        self.move_car = move_car\n",
        "        self.rotate_car = rotate_car\n",
        "        self.zoom_car = zoom_car\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        filename = self.filenames[index]\n",
        "        arr = np.load(os.path.join(self.root, filename))\n",
        "        photo_mod = True\n",
        "        if 'photo' in filename:\n",
        "            # Photos only get new background with 33% chance\n",
        "            photo_mod = random.randrange(0,3)==1\n",
        "\n",
        "        if self.move_car:\n",
        "            x = random.randrange(80,255-80)\n",
        "            y = random.randrange(80,255-80)\n",
        "            angle = random.randrange(-30,30) if self.rotate_car else 0\n",
        "            zoom = random.uniform(0.8,1.4) if self.zoom_car else 1\n",
        "            arr = move_full_car(arr, x, y, angle, zoom)\n",
        "\n",
        "        car = arr[:,:,0:3]\n",
        "        labels = arr[:,:,3]\n",
        "\n",
        "        if len(self.backgrounds) > 0 and photo_mod:\n",
        "            rand_idx = random.randrange(0,len(self.backgrounds))\n",
        "\n",
        "            # Some backgrounds are RGB\n",
        "            img = self.backgrounds[rand_idx]\n",
        "            car = set_background(car, labels, img)\n",
        "\n",
        "        car = np.moveaxis(car, 2, 0)\n",
        "\n",
        "        return car, labels/10"
      ],
      "metadata": {
        "id": "-CwLF9TZCOJL"
      },
      "id": "-CwLF9TZCOJL",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "black_car = []\n",
        "orange_car = []\n",
        "photos = []\n",
        "for file in os.listdir(f'{drive_path}carseg_data/arrays'):\n",
        "    if 'orange' in file: orange_car.append(file)\n",
        "    elif 'black' in file: black_car.append(file)\n",
        "    elif 'photo' in file and '(' not in file: photos.append(file)\n",
        "\n",
        "root = f'{drive_path}carseg_data/arrays'\n",
        "\n",
        "\n",
        "photo_test = photos[:30]\n",
        "photos = photos[30:]\n",
        "\n",
        "black_train, _ = train_test_split(black_car, test_size=0.1, random_state=42, shuffle=True)\n",
        "orange_train, _ = train_test_split(orange_car, test_size=0.1, random_state=42, shuffle=True)\n",
        "photos_train, photos_val = train_test_split(photos, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "\n",
        "photos_train_ds = CarDataset(root, photos_train*3)\n",
        "train1_ds = CarDataset(root, photos_train, rotate_car=True, move_car=True)\n",
        "train2_ds = CarDataset(root, black_train[:100]+orange_train[:100], backgrounds=background_list)\n",
        "\n",
        "val_ds = CarDataset(root, photos_val)\n",
        "test_ds = CarDataset(root, photo_test)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(photos_train_ds+train1_ds+train2_ds, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=16)\n",
        "test_loader =  DataLoader(test_ds, batch_size=16)\n"
      ],
      "metadata": {
        "id": "zRX1q0M_RY9R"
      },
      "id": "zRX1q0M_RY9R",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.3),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        for layer in self.block:\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                init.kaiming_normal_(layer.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.encoder0 = nn.Sequential(ConvBlock(in_channels, 64))\n",
        "        self.encoder1 = nn.Sequential(nn.MaxPool2d(2,2), ConvBlock(64, 128))\n",
        "        self.encoder2 = nn.Sequential(nn.MaxPool2d(2,2), ConvBlock(128, 256))\n",
        "        self.encoder3 = nn.Sequential(nn.MaxPool2d(2,2), ConvBlock(256, 512))\n",
        "        self.bottleneck = nn.Sequential(nn.MaxPool2d(2,2), ConvBlock(512,1024), nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2))\n",
        "        self.decoder0 = nn.Sequential(ConvBlock(1024,512), nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2))\n",
        "        self.decoder1 = nn.Sequential(ConvBlock(512,256), nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2))\n",
        "        self.decoder2 = nn.Sequential(ConvBlock(256,128), nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2))\n",
        "        self.decoder3 = nn.Sequential(ConvBlock(128,64), nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.encoder0(x)\n",
        "        x1 = self.encoder1(x0)\n",
        "        x2 = self.encoder2(x1)\n",
        "        x3 = self.encoder3(x2)\n",
        "        x4 = self.bottleneck(x3)\n",
        "        x4 = self.decoder0(torch.cat([x3,x4],dim=1))\n",
        "        x4 = self.decoder1(torch.cat([x2,x4],dim=1))\n",
        "        x4 = self.decoder2(torch.cat([x1,x4],dim=1))\n",
        "        x4 = self.decoder3(torch.cat([x0,x4],dim=1))\n",
        "\n",
        "        return x4"
      ],
      "metadata": {
        "id": "1kNd_9agvsB5"
      },
      "id": "1kNd_9agvsB5",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model = UNet(3, 10).to(device)"
      ],
      "metadata": {
        "id": "mTOh4IglxbHw"
      },
      "id": "mTOh4IglxbHw",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
      ],
      "metadata": {
        "id": "PeWijAip7nDh"
      },
      "id": "PeWijAip7nDh",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "dice = Dice(average='micro')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "    dice_scores_train = []\n",
        "\n",
        "\n",
        "    for batch in train_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.long().to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Calculate dice\n",
        "        _, pred = torch.max(outputs, 1)\n",
        "        pred_cpu = pred.to('cpu')\n",
        "        labels_cpu = labels.to('cpu')\n",
        "\n",
        "        dice_scores_train.append(dice(pred_cpu, labels_cpu))\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0.0\n",
        "    dice_scores_val = []\n",
        "\n",
        "    for batch in val_loader:\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        inputs = inputs.float()\n",
        "        labels = labels.long().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            val_loss = criterion(outputs, labels)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "            # Calculate dice\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            pred_cpu = pred.to('cpu')\n",
        "            labels_cpu = labels.to('cpu')\n",
        "\n",
        "            dice_scores_val.append(dice(pred_cpu, labels_cpu))\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {(total_train_loss / len(train_loader)):.4f}, Train dice: {np.mean(dice_scores_train):.4f}, Val Loss: {(total_val_loss / len(val_loader)):.4f}, Val dice: {np.mean(dice_scores_val):.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ugfQCb45aC-",
        "outputId": "6cee3d1b-66bf-4e76-8ba5-d3f68a71b9be"
      },
      "id": "8ugfQCb45aC-",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 1.7990, Train dice: 0.5354, Val Loss: 1.2098, Val dice: 0.6678\n",
            "Epoch 2/100, Train Loss: 1.1303, Train dice: 0.6750, Val Loss: 0.9697, Val dice: 0.7257\n",
            "Epoch 3/100, Train Loss: 0.9418, Train dice: 0.7107, Val Loss: 0.9399, Val dice: 0.7140\n",
            "Epoch 4/100, Train Loss: 0.8970, Train dice: 0.7164, Val Loss: 0.9500, Val dice: 0.7337\n",
            "Epoch 5/100, Train Loss: 0.8484, Train dice: 0.7318, Val Loss: 0.8559, Val dice: 0.7543\n",
            "Epoch 6/100, Train Loss: 0.8317, Train dice: 0.7366, Val Loss: 0.8420, Val dice: 0.7382\n",
            "Epoch 7/100, Train Loss: 0.8121, Train dice: 0.7385, Val Loss: 0.8187, Val dice: 0.7535\n",
            "Epoch 8/100, Train Loss: 0.7968, Train dice: 0.7462, Val Loss: 0.8133, Val dice: 0.7579\n",
            "Epoch 9/100, Train Loss: 0.7834, Train dice: 0.7501, Val Loss: 0.8275, Val dice: 0.7533\n",
            "Epoch 10/100, Train Loss: 0.7384, Train dice: 0.7613, Val Loss: 0.8266, Val dice: 0.7514\n",
            "Epoch 11/100, Train Loss: 0.7307, Train dice: 0.7633, Val Loss: 0.8168, Val dice: 0.7625\n",
            "Epoch 12/100, Train Loss: 0.7069, Train dice: 0.7701, Val Loss: 0.7547, Val dice: 0.7745\n",
            "Epoch 13/100, Train Loss: 0.6926, Train dice: 0.7735, Val Loss: 0.7897, Val dice: 0.7317\n",
            "Epoch 14/100, Train Loss: 0.6714, Train dice: 0.7787, Val Loss: 0.7737, Val dice: 0.7739\n",
            "Epoch 15/100, Train Loss: 0.6630, Train dice: 0.7829, Val Loss: 0.7919, Val dice: 0.7435\n",
            "Epoch 16/100, Train Loss: 0.6333, Train dice: 0.7918, Val Loss: 0.7592, Val dice: 0.7757\n",
            "Epoch 17/100, Train Loss: 0.6199, Train dice: 0.7971, Val Loss: 0.7394, Val dice: 0.7819\n",
            "Epoch 18/100, Train Loss: 0.5911, Train dice: 0.8049, Val Loss: 0.6438, Val dice: 0.8015\n",
            "Epoch 19/100, Train Loss: 0.5739, Train dice: 0.8110, Val Loss: 0.6363, Val dice: 0.7935\n",
            "Epoch 20/100, Train Loss: 0.5700, Train dice: 0.8128, Val Loss: 0.6598, Val dice: 0.8027\n",
            "Epoch 21/100, Train Loss: 0.5466, Train dice: 0.8205, Val Loss: 0.7393, Val dice: 0.7825\n",
            "Epoch 22/100, Train Loss: 0.5342, Train dice: 0.8247, Val Loss: 0.6200, Val dice: 0.8045\n",
            "Epoch 23/100, Train Loss: 0.5162, Train dice: 0.8286, Val Loss: 0.6090, Val dice: 0.8156\n",
            "Epoch 24/100, Train Loss: 0.5091, Train dice: 0.8326, Val Loss: 0.6743, Val dice: 0.8055\n",
            "Epoch 25/100, Train Loss: 0.4958, Train dice: 0.8354, Val Loss: 0.6726, Val dice: 0.7904\n",
            "Epoch 26/100, Train Loss: 0.4727, Train dice: 0.8432, Val Loss: 0.6466, Val dice: 0.8134\n",
            "Epoch 27/100, Train Loss: 0.4663, Train dice: 0.8424, Val Loss: 0.6393, Val dice: 0.8065\n",
            "Epoch 28/100, Train Loss: 0.4428, Train dice: 0.8515, Val Loss: 0.6319, Val dice: 0.7964\n",
            "Epoch 29/100, Train Loss: 0.4450, Train dice: 0.8500, Val Loss: 0.6423, Val dice: 0.8074\n",
            "Epoch 30/100, Train Loss: 0.4320, Train dice: 0.8549, Val Loss: 0.5960, Val dice: 0.8160\n",
            "Epoch 31/100, Train Loss: 0.4245, Train dice: 0.8564, Val Loss: 0.5337, Val dice: 0.8334\n",
            "Epoch 32/100, Train Loss: 0.4076, Train dice: 0.8609, Val Loss: 0.5775, Val dice: 0.8129\n",
            "Epoch 33/100, Train Loss: 0.4021, Train dice: 0.8631, Val Loss: 0.5592, Val dice: 0.8293\n",
            "Epoch 34/100, Train Loss: 0.3874, Train dice: 0.8678, Val Loss: 0.6077, Val dice: 0.8217\n",
            "Epoch 35/100, Train Loss: 0.3835, Train dice: 0.8676, Val Loss: 0.5592, Val dice: 0.8198\n",
            "Epoch 36/100, Train Loss: 0.3792, Train dice: 0.8674, Val Loss: 0.5613, Val dice: 0.8193\n",
            "Epoch 37/100, Train Loss: 0.3689, Train dice: 0.8732, Val Loss: 0.6381, Val dice: 0.8219\n",
            "Epoch 38/100, Train Loss: 0.3410, Train dice: 0.8806, Val Loss: 0.5432, Val dice: 0.8290\n",
            "Epoch 39/100, Train Loss: 0.3340, Train dice: 0.8835, Val Loss: 0.6846, Val dice: 0.8206\n",
            "Epoch 40/100, Train Loss: 0.3383, Train dice: 0.8820, Val Loss: 0.6237, Val dice: 0.8245\n",
            "Epoch 41/100, Train Loss: 0.3388, Train dice: 0.8824, Val Loss: 0.5938, Val dice: 0.8160\n",
            "Epoch 42/100, Train Loss: 0.3417, Train dice: 0.8807, Val Loss: 0.5083, Val dice: 0.8305\n",
            "Epoch 43/100, Train Loss: 0.3144, Train dice: 0.8900, Val Loss: 0.6019, Val dice: 0.8266\n",
            "Epoch 44/100, Train Loss: 0.3161, Train dice: 0.8903, Val Loss: 0.5795, Val dice: 0.8349\n",
            "Epoch 45/100, Train Loss: 0.2976, Train dice: 0.8958, Val Loss: 0.5155, Val dice: 0.8386\n",
            "Epoch 46/100, Train Loss: 0.2867, Train dice: 0.8998, Val Loss: 0.5441, Val dice: 0.8350\n",
            "Epoch 47/100, Train Loss: 0.2960, Train dice: 0.8975, Val Loss: 0.5202, Val dice: 0.8325\n",
            "Epoch 48/100, Train Loss: 0.2944, Train dice: 0.8977, Val Loss: 0.5674, Val dice: 0.8252\n",
            "Epoch 49/100, Train Loss: 0.2819, Train dice: 0.9020, Val Loss: 0.5144, Val dice: 0.8398\n",
            "Epoch 50/100, Train Loss: 0.2718, Train dice: 0.9046, Val Loss: 0.5314, Val dice: 0.8408\n",
            "Epoch 51/100, Train Loss: 0.2881, Train dice: 0.9023, Val Loss: 0.5217, Val dice: 0.8413\n",
            "Epoch 52/100, Train Loss: 0.2757, Train dice: 0.9043, Val Loss: 0.5495, Val dice: 0.8398\n",
            "Epoch 53/100, Train Loss: 0.2585, Train dice: 0.9105, Val Loss: 0.6037, Val dice: 0.8419\n",
            "Epoch 54/100, Train Loss: 0.2414, Train dice: 0.9165, Val Loss: 0.4899, Val dice: 0.8508\n",
            "Epoch 55/100, Train Loss: 0.2408, Train dice: 0.9168, Val Loss: 0.6138, Val dice: 0.8409\n",
            "Epoch 56/100, Train Loss: 0.2513, Train dice: 0.9141, Val Loss: 0.5241, Val dice: 0.8509\n",
            "Epoch 57/100, Train Loss: 0.2426, Train dice: 0.9162, Val Loss: 0.5341, Val dice: 0.8445\n",
            "Epoch 58/100, Train Loss: 0.2258, Train dice: 0.9226, Val Loss: 0.4987, Val dice: 0.8489\n",
            "Epoch 59/100, Train Loss: 0.2266, Train dice: 0.9217, Val Loss: 0.5293, Val dice: 0.8428\n",
            "Epoch 60/100, Train Loss: 0.2237, Train dice: 0.9236, Val Loss: 0.5033, Val dice: 0.8501\n",
            "Epoch 61/100, Train Loss: 0.2363, Train dice: 0.9191, Val Loss: 0.5048, Val dice: 0.8427\n",
            "Epoch 62/100, Train Loss: 0.2141, Train dice: 0.9263, Val Loss: 0.4877, Val dice: 0.8548\n",
            "Epoch 63/100, Train Loss: 0.2013, Train dice: 0.9308, Val Loss: 0.5162, Val dice: 0.8496\n",
            "Epoch 64/100, Train Loss: 0.1985, Train dice: 0.9317, Val Loss: 0.5617, Val dice: 0.8466\n",
            "Epoch 65/100, Train Loss: 0.2155, Train dice: 0.9270, Val Loss: 0.4883, Val dice: 0.8558\n",
            "Epoch 66/100, Train Loss: 0.1913, Train dice: 0.9340, Val Loss: 0.4831, Val dice: 0.8592\n",
            "Epoch 67/100, Train Loss: 0.1978, Train dice: 0.9323, Val Loss: 0.5086, Val dice: 0.8495\n",
            "Epoch 68/100, Train Loss: 0.2043, Train dice: 0.9293, Val Loss: 0.5374, Val dice: 0.8543\n",
            "Epoch 69/100, Train Loss: 0.2033, Train dice: 0.9307, Val Loss: 0.4761, Val dice: 0.8579\n",
            "Epoch 70/100, Train Loss: 0.2033, Train dice: 0.9300, Val Loss: 0.5195, Val dice: 0.8529\n",
            "Epoch 71/100, Train Loss: 0.2036, Train dice: 0.9295, Val Loss: 0.5929, Val dice: 0.8428\n",
            "Epoch 72/100, Train Loss: 0.1888, Train dice: 0.9352, Val Loss: 0.5210, Val dice: 0.8541\n",
            "Epoch 73/100, Train Loss: 0.1825, Train dice: 0.9370, Val Loss: 0.5224, Val dice: 0.8582\n",
            "Epoch 74/100, Train Loss: 0.1746, Train dice: 0.9391, Val Loss: 0.5248, Val dice: 0.8610\n",
            "Epoch 75/100, Train Loss: 0.1753, Train dice: 0.9387, Val Loss: 0.5025, Val dice: 0.8603\n",
            "Epoch 76/100, Train Loss: 0.1640, Train dice: 0.9426, Val Loss: 0.5150, Val dice: 0.8613\n",
            "Epoch 77/100, Train Loss: 0.1655, Train dice: 0.9422, Val Loss: 0.4984, Val dice: 0.8634\n",
            "Epoch 78/100, Train Loss: 0.1564, Train dice: 0.9443, Val Loss: 0.5566, Val dice: 0.8508\n",
            "Epoch 79/100, Train Loss: 0.1610, Train dice: 0.9435, Val Loss: 0.5103, Val dice: 0.8633\n",
            "Epoch 80/100, Train Loss: 0.1641, Train dice: 0.9430, Val Loss: 0.4996, Val dice: 0.8655\n",
            "Epoch 81/100, Train Loss: 0.1643, Train dice: 0.9430, Val Loss: 0.5213, Val dice: 0.8608\n",
            "Epoch 82/100, Train Loss: 0.1564, Train dice: 0.9446, Val Loss: 0.4901, Val dice: 0.8657\n",
            "Epoch 83/100, Train Loss: 0.1576, Train dice: 0.9445, Val Loss: 0.6496, Val dice: 0.8461\n",
            "Epoch 84/100, Train Loss: 0.1576, Train dice: 0.9447, Val Loss: 0.4865, Val dice: 0.8655\n",
            "Epoch 85/100, Train Loss: 0.1441, Train dice: 0.9488, Val Loss: 0.4836, Val dice: 0.8695\n",
            "Epoch 86/100, Train Loss: 0.1433, Train dice: 0.9489, Val Loss: 0.5206, Val dice: 0.8673\n",
            "Epoch 87/100, Train Loss: 0.1442, Train dice: 0.9488, Val Loss: 0.4721, Val dice: 0.8683\n",
            "Epoch 88/100, Train Loss: 0.1475, Train dice: 0.9478, Val Loss: 0.4956, Val dice: 0.8674\n",
            "Epoch 89/100, Train Loss: 0.1409, Train dice: 0.9500, Val Loss: 0.5023, Val dice: 0.8656\n",
            "Epoch 90/100, Train Loss: 0.1395, Train dice: 0.9501, Val Loss: 0.5048, Val dice: 0.8669\n",
            "Epoch 91/100, Train Loss: 0.1411, Train dice: 0.9498, Val Loss: 0.6183, Val dice: 0.8536\n",
            "Epoch 92/100, Train Loss: 0.1512, Train dice: 0.9472, Val Loss: 0.4845, Val dice: 0.8735\n",
            "Epoch 93/100, Train Loss: 0.1412, Train dice: 0.9501, Val Loss: 0.4568, Val dice: 0.8735\n",
            "Epoch 94/100, Train Loss: 0.1497, Train dice: 0.9470, Val Loss: 0.5288, Val dice: 0.8660\n",
            "Epoch 95/100, Train Loss: 0.1490, Train dice: 0.9474, Val Loss: 0.5306, Val dice: 0.8616\n",
            "Epoch 96/100, Train Loss: 0.1450, Train dice: 0.9486, Val Loss: 0.5938, Val dice: 0.8588\n",
            "Epoch 97/100, Train Loss: 0.1434, Train dice: 0.9486, Val Loss: 0.5643, Val dice: 0.8621\n",
            "Epoch 98/100, Train Loss: 0.1390, Train dice: 0.9507, Val Loss: 0.5009, Val dice: 0.8739\n",
            "Epoch 99/100, Train Loss: 0.1321, Train dice: 0.9526, Val Loss: 0.4770, Val dice: 0.8738\n",
            "Epoch 100/100, Train Loss: 0.1357, Train dice: 0.9514, Val Loss: 0.4806, Val dice: 0.8722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, loader):\n",
        "  \"\"\"Test a model on a test dataset\"\"\"\n",
        "  dice = Dice(average='micro')\n",
        "  model.eval()\n",
        "  dice_scores = []\n",
        "\n",
        "  for batch in loader:\n",
        "      inputs, labels = batch\n",
        "      inputs, labels = batch\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      inputs = inputs.float()\n",
        "      labels = labels.long().to(device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          outputs = model(inputs)\n",
        "\n",
        "          # Calculate accuracy on the test set\n",
        "          _, pred = torch.max(outputs, 1)\n",
        "\n",
        "          # Move tensors to CPU before performing numpy operations\n",
        "          pred_cpu = pred.to('cpu')\n",
        "          labels_cpu = labels.to('cpu')\n",
        "\n",
        "          dice_scores.append(dice(pred_cpu, labels_cpu))\n",
        "\n",
        "  return np.mean(dice_scores)\n",
        "\n"
      ],
      "metadata": {
        "id": "xQaY9sY_cI_V"
      },
      "id": "xQaY9sY_cI_V",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ_nju9sx2RG",
        "outputId": "5c1efc25-f7aa-4361-fdb2-f1bfd7a98d3d"
      },
      "id": "XJ_nju9sx2RG",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8916156"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), f'{drive_path}carseg_data/model3.pth')"
      ],
      "metadata": {
        "id": "nSig9FTq9wpq"
      },
      "id": "nSig9FTq9wpq",
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Original\n",
        "\n",
        "Photos: 0.8259544\\\n",
        "Black: 0.9816798\\\n",
        "Orange: 0.98628855\\\n",
        "Test: 0.9728253"
      ],
      "metadata": {
        "id": "jO5exdysxHFk"
      },
      "id": "jO5exdysxHFk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Added photos\n",
        "\n",
        "Photos: 0.83027714\\\n",
        "Black: 0.9769864\\\n",
        "Orange: 0.98165745\\\n",
        "Test: 0.9720461"
      ],
      "metadata": {
        "id": "04qmVMsGGH9h"
      },
      "id": "04qmVMsGGH9h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Added photos and background\n",
        "\n",
        "Photos: 0.8418195\\\n",
        "Black: 0.9842939\\\n",
        "Orange: 0.9854847\\\n",
        "Test: 0.97684497\n",
        "\n"
      ],
      "metadata": {
        "id": "kGmyT6xBIg_9"
      },
      "id": "kGmyT6xBIg_9"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}